{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Creating tensors",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### The first thing we're going to create is a **scalar**. A scalar is a **single number** and in tensor-speak it's a zero dimension tensor.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scalar = torch.tensor(7)\nscalar",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor(7)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can check the **dimensions of a tensor** using the ```ndim``` attribute.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scalar.ndim",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: 0",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "What if we wanted to **retrieve** the number from the tensor? To do we can use the ```item()``` method.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scalar.item()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: 7",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Now let's see a **vector**. A vector is a **single dimension** tensor but can contain many numbers.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "vector = torch.tensor([7, 7])\nvector",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([7, 7])",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "vector.ndim",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: 1",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can tell **the number of dimensions a tensor** in Pytorch has by **the number of square brackets on the outside**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Another important concept for tensors is their ```shape``` attribute. The shape tells you **how the elements inside them are arranged**.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "vector.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: torch.Size([2])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Our vector has a shape of ```[2]```. This is because of **the two elements we placed inside the square brackets**.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Now let's see a **matrix**.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "MATRIX = torch.tensor([[7, 8],\n                       [9, 10]])\nMATRIX",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([[ 7,  8],\r\n                [ 9, 10]])",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "MATRIX.ndim",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: 2",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "MATRIX.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: torch.Size([2, 2])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### How about we create a **tensor**?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "TENSOR = torch.tensor([[[1, 2, 3],\n                        [3, 6, 9],\n                        [2, 4, 5]]])\nTENSOR",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "TENSOR.ndim",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: 3",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "TENSOR.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: torch.Size([1, 3, 3])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Random tensors",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can create a tensor of random numbers using ```torch.rand()``` and passing in the ```size``` parameter.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "random_tensor = torch.rand(size=(3, 4))\nrandom_tensor, random_tensor.dtype",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([[0.6541, 0.4807, 0.2162, 0.6168],\r\n         [0.4428, 0.6608, 0.6194, 0.8620],\r\n         [0.2795, 0.6055, 0.4958, 0.5483]]),\r\n torch.float32)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The flexibility of ```torch.rand()``` is that we can adjust the ```size``` to be whatever we want. For example, you want a random tensor in the common image shape of ```[224, 224, 3]``` ```([height, width, channels])```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "random_image_size_tensor = torch.rand(size=(224, 224, 3))\nrandom_image_size_tensor.shape, random_image_size_tensor.ndim",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (torch.Size([224, 224, 3]), 3)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Zeros and ones",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This happens a lot with masking (like masking some of the values in one tensor with zeros to **let a model know not to learn them**). Let's create a tensor full of zeros with ```torch.zeros()```. Again, the ```size``` parameter comes into play. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "zeros = torch.zeros(size=(3, 4))\nzeros, zeros.dtype",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([[0., 0., 0., 0.],\r\n         [0., 0., 0., 0.],\r\n         [0., 0., 0., 0.]]),\r\n torch.float32)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Creating a range and tensors like",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100. You can use ```torch.arange(start, end, step)``` to do so.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "zero_to_ten = torch.arange(start=0, end=10, step=1)\nzero_to_ten",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Sometimes you might want one tensor of a certain type with the same shape as another tensor. To do so you can use ```torch.zeros_like(input)``` or ```torch.ones_like(input)``` which return a tensor filled with zeros or ones in the same shape as the ```input``` respectively.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ten_zeros = torch.zeros_like(input=zero_to_ten)\nten_zeros",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Getting information from tensors",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Three of the most common attributes you'll want to find out about tensors are:\n1. ```shape```\n2. ```dtype```\n3. ```device```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "some_tensor = torch.rand(3, 4)\n\nprint(some_tensor)\nprint(f\"Shape of tensor: {some_tensor.shape}\")\nprint(f\"Datatype of tensor: {some_tensor.dtype}\")\nprint(f\"Device tensor is stored on: {some_tensor.device}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([[0.4688, 0.0055, 0.8551, 0.0646],\r\n        [0.6538, 0.5157, 0.4071, 0.2109],\r\n        [0.9960, 0.3061, 0.9369, 0.7008]])\r\nShape of tensor: torch.Size([3, 4])\r\nDatatype of tensor: torch.float32\r\nDevice tensor is stored on: cpu",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Matrix multiplication",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Pytorch implements matrix multiplication in the ```torch.matmul()``` method. **You can also use ```torch.mm()``` which is a short for ```torch.matmul()```.**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\ntensor = torch.tensor([1, 2, 3])\ntensor.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: torch.Size([3])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Operation                  | Calculation                            | Code                       |\n|---------------------------|----------------------------------------|----------------------------|\n|Element-wise multiplication| ```[1*1, 2*2, 3*3]``` = ```[1, 4, 9]```| ```tensor * tensor```      |\n|Matrix multiplication      | ```[1*1 + 2*2 + 3*3]``` = ```[14]```   | ```tensor.matmul(tensor)```|",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tensor.matmul(tensor, tensor)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "tensor(14)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "One of the ways to do this is with a **transpose** (switch the dimensions of a given tensor). You can use ```tensor.T``` - where ```tensor``` is the desired tensor to transpose.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Finding the min, max, mean, sum, etc",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First we'll create a tensor and then find the max, min, mean and sum of it.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "x = tensor.arange(0, 100, 10)\nprint(f\"Minimum: {x.min()}\")\nprint(f\"Maximum: {x.max()}\")\n# print(f\"Mean: {x.mean()}\") # this will error\nprint(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\nprint(f\"Sum: {x.sum()}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: Minimum: 0\r\nMaximum: 90\r\nMean: 45.0\r\nSum: 450",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Note:** You may find some methods such as ```torch.mean()``` require tensors to be in ```torch.float32``` (the most common) or another specific datatype, otherwise the operation will fail.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Positional min/max",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can also find the index of a tensor where the max or minimum occurs with ```torch.argmax()``` and ```torch.argmin()``` respectively.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tensor = torch.arange(10, 100, 10)\n\n# Returns index of max and min values\nprint(f\"Index where max value occurs: {tensor.argmax()}\")\nprint(f\"Index where min value occurs: {tensor.argmin()}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\r\nIndex where max value occurs: 8\r\nIndex where min value occurs: 0",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Change tensor datatype",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can change the datatype of tensors using ```torch.Tensor.type(dtype=None)``` where the ```dtype``` parameter is the datatype you'd like to use.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tensor = torch.arange(10., 100., 10.)\ntensor.dtype",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: torch.float32",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tensor_float16 = tensor.type(torch.float16)\ntensor_float16",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Reshaping, stacking, squeezing and unsqueezing",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Method                             |                                                                                                      Description|\n|-----------------------------------|-----------------------------------------------------------------------------------------------------------------|\n|```torch.reshape(input, shape)```  |                  Reshapes ```input``` to ```shape``` (if compatible), can also use ```torch.Tensor.reshape()```.|\n|```Tensor.view(shape)```           |Returns a view of the original tensor in a different ```shape``` but shares the same data as the original tensor.|\n|```torch.stack(tensors, dim=0)```  | Concatenates a sequence of ```tensors``` along a new dimension (```dim```), all ```tensors``` must be same size.|\n|```tensor.squeeze(input)```        |                                             Squeezes ```input``` to remove all the dimenions with value ```1```.|\n|```tensor.unsqueeze(input, dim)``` |                                        Returns ```input``` with a dimension value of ```1``` added at ```dim```.|\n|```torch.permute(input, dims)```   |              Returns a view of the original ```input``` with its dimensions permuted (rearranged) to ```dims```.|",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nx = torch.arange(1., 8.)\nx, x.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Add an extra dimension\nx_reshaped = x.reshape(1, 7)\nx_reshaped, x_reshaped.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can also change the view with ```torch.view()```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "z = x.view(1, 7)\nz, z.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Remember though, changing the view of a tensor with ```torch.view()``` really only creates a new view of the same tensor. **So changing the view changes the original tensor too.**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Changing z changes x\nz[:, 0] = 5\nz, x",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "If we wanted to stack our new tensor on top of itself five times, we could do so with ```tensor.stack()```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Stack tensors on top of each other\nx_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\nx_stacked",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([[5., 2., 3., 4., 5., 6., 7.],\r\n        [5., 2., 3., 4., 5., 6., 7.],\r\n        [5., 2., 3., 4., 5., 6., 7.],\r\n        [5., 2., 3., 4., 5., 6., 7.]])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "How about **removing all single dimensions from a tensor**? To do so you can use ```torch.squeeze()```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(f\"Previous tensor: {x_reshaped}\")\nprint(f\"Previous shape: {x_reshaped.shape}\")\n\n# Remove extra dimension from x_reshaped\nx_squeezed = x_reshaped.squeeze()\nprint(f\"\\nNew tensor: {x_squeezed}\")\nprint(f\"New shape: {x_squeezed.shape}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\r\nPrevious shape: torch.Size([1, 7])\r\n\r\nNew tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\r\nNew shape: torch.Size([7])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "And to do the **reverse** of ```torch.squeeze()``` you can use ```torch.unsqueezq()``` to add a dimension value of 1 at a specific index.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(f\"Previous tensor: {x_squeezed}\")\nprint(f\"Previous shape: {x_squeezed.shape}\")\n\n## Add an extra dimension with unsqueeze\nx_unsqueezed = x_squeezed.unsqueeze(dim=0)\nprint(f\"\\nNew tensor: {x_unsqueezed}\")\nprint(f\"New shape: {x_unsqueezed.shape}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\r\nPrevious shape: torch.Size([7])\r\n\r\nNew tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\r\nNew shape: torch.Size([1, 7])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can also **rearrange the order of axes values** with ```torch.permute(input, dims)```, where the ```input``` gets turned into a view with new ```dims```.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create tensor with specific shape\nx_original = torch.rand(size=(224, 224, 3))\n\n# Permute the original tensor to rearrange the axis order\nx_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n\nprint(f\"Previous shape: {x_original.shape}\")\nprint(f\"New shape: {x_permuted.shape}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: Previous shape: torch.Size([224, 224, 3])\r\nNew shape: torch.Size([3, 224, 224])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Because permuting returns a view (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original.**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Indexing(selecting data from tensors)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a tensor \nimport torch\nx = torch.arange(1, 10).reshape(1, 3, 3)\nx, x.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([[[1, 2, 3],\r\n          [4, 5, 6],\r\n          [7, 8, 9]]]),\r\n torch.Size([1, 3, 3]))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\nIndexing values goes outer dimension -> inner dimension (check out the square brackets).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Let's index bracket by bracket\nprint(f\"First square bracket:\\n{x[0]}\") \nprint(f\"Second square bracket: {x[0][0]}\") \nprint(f\"Third square bracket: {x[0][0][0]}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "First square bracket:\r\ntensor([[1, 2, 3],\r\n        [4, 5, 6],\r\n        [7, 8, 9]])\r\nSecond square bracket: tensor([1, 2, 3])\r\nThird square bracket: 1et: 1cket: 1",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can also use ```:``` to specify \"all values in this dimension\" and then use a comma (```,```) to add another dimension.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get all values of 0th dimension and the 0 index of 1st dimension\nx[:, 0]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([[1, 2, 3]])",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\nx[:, :, 1]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([[2, 5, 8]])",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\nx[:, 1, 1]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([5])",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \nx[0, 0, :] # same as x[0][0]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([1, 2, 3])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### PyTorch tensors & Numpy",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The two main methods you'll want to use for NumPy to PyTorch are:\n1. ```torch.from_numpy(ndarray)``` - NumPy array -> PyTorch tensor\n2. ```torch.Tensor.numpy()``` - PyTorch tensor -> NumPy array",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport numpy as np\narray = np.arange(1.0, 8.0)\ntensor = torch.from_numpy(array)\narray, tensor",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (array([1., 2., 3., 4., 5., 6., 7.]),\r\n tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Because we reassigned ```tensor``` above, if you change the tensor, the array stays the same.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Reproducibility (trying to take the random out of random)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "What if you want to creat two random tensors with **the same values**. As in, the tensors would still contain random values but they would be of the same flavour. That's where ```torch.manual_seed(seed)``` comes in, where ```seed``` is an integer that flavours the randomness.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport random\n\nRANDOM_SEED = 42\ntorch.manual_seed(seed=RANDOM_SEED)\nrandom_tensor_C = torch.rand(3, 4)\n\n# Have to reset the seed every time a new rand() is called \ntorch.random.manual_seed(seed=RANDOM_SEED)\nrandom_tensor_D = torch.rand(3, 4)\n\nprint(f\"Tensor C:\\n{random_tensor_C}\\n\")\nprint(f\"Tensor D:\\n{random_tensor_D}\\n\")\nprint(f\"Does Tensor C equal Tensor D? (anywhere)\")\nrandom_tensor_C == random_tensor_D",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: Tensor C:\r\ntensor([[0.8823, 0.9150, 0.3829, 0.9593],\r\n        [0.3904, 0.6009, 0.2566, 0.7936],\r\n        [0.9408, 0.1332, 0.9346, 0.5936]])\r\n\r\nTensor D:\r\ntensor([[0.8823, 0.9150, 0.3829, 0.9593],\r\n        [0.3904, 0.6009, 0.2566, 0.7936],\r\n        [0.9408, 0.1332, 0.9346, 0.5936]])\r\n\r\nDoes Tensor C equal Tensor D? (anywhere)\r\ntensor([[True, True, True, True],\r\n        [True, True, True, True],\r\n        [True, True, True, True]])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Running tensors on GPUs",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### 1. Getting a GPU",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To check if you've got access to a Nvidia GPU, you can run ```!nvidia-smi``` where the ```!``` means \"run this on the command line\".",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### 2. Getting PyTorch to run on the GPU",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Getting PyTorch to use for storing data and computing on data. To do so, you can use the ```torch.cuda``` package.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\ntorch.cuda.is_available()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: True",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's create a ```device``` variable to store what kind of device is available.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: 'cuda'",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can count the number of GPUs PyTorch has access to using ```torch.cuda.device_count()```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "torch.cuda.device_count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: 1",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### 3. Putting tensors(and models) on the GPU",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can put tensors(and models) on a specific device by calling ```to(device)``` on them.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tensor = torch.tensor([1, 2, 3])\n\ntensor_on_gpu = tensor.to(device)\ntensor_on_gpu",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([1, 2, 3], device='cuda:0')",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "##### 4. Moving tensors back to the CPU",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To **get back to CPU** we can use ```Tensor.cpu()```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\ntensor_back_on_cpu",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: array([1, 2, 3])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\nThe above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tensor_on_gpu",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: tensor([1, 2, 3], device='cuda:0')",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}