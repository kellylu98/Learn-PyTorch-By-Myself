Topic	Contents
**Introduction to tensors**:	Tensors are the basic building block of all of machine learning and deep learning.
**Creating tensors**:	Tensors can represent almost any kind of data (images, words, tables of numbers).
**Getting information from tensors**:	If you can put information into a tensor, you'll want to get it out too.
**Manipulating tensors**:	Machine learning algorithms (like neural networks) involve manipulating tensors in many different ways such as adding, multiplying, combining.
**Dealing with tensor shapes**:	One of the most common issues in machine learning is dealing with shape mismatches (trying to mixed wrong shaped tensors with other tensors).
**Indexing on tensors**:	If you've indexed on a Python list or NumPy array, it's very similar with tensors, except they can have far more dimensions.
**Mixing PyTorch tensors and NumPy**:	PyTorch plays with tensors (torch.Tensor), NumPy likes arrays (np.ndarray) sometimes you'll want to mix and match these.
**Reproducibility**:	Machine learning is very experimental and since it uses a lot of randomness to work, sometimes you'll want that randomness to not be so random.
**Running tensors on GPU**:	GPUs (Graphics Processing Units) make your code faster, PyTorch makes it easy to run your code on GPUs.
