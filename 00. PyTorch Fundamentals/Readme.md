Topic	Contents
1. **Introduction to tensors**:	Tensors are the basic building block of all of machine learning and deep learning.
2. **Creating tensors**:	Tensors can represent almost any kind of data (images, words, tables of numbers).
3. **Getting information from tensors**:	If you can put information into a tensor, you'll want to get it out too.
4. **Manipulating tensors**:	Machine learning algorithms (like neural networks) involve manipulating tensors in many different ways such as adding, multiplying, combining.
5. **Dealing with tensor shapes**:	One of the most common issues in machine learning is dealing with shape mismatches (trying to mixed wrong shaped tensors with other tensors).
6. **Indexing on tensors**:	If you've indexed on a Python list or NumPy array, it's very similar with tensors, except they can have far more dimensions.
7. **Mixing PyTorch tensors and NumPy**:	PyTorch plays with tensors (torch.Tensor), NumPy likes arrays (np.ndarray) sometimes you'll want to mix and match these.
8. **Reproducibility**:	Machine learning is very experimental and since it uses a lot of randomness to work, sometimes you'll want that randomness to not be so random.
9. **Running tensors on GPU**:	GPUs (Graphics Processing Units) make your code faster, PyTorch makes it easy to run your code on GPUs.
