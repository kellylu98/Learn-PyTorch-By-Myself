{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## 01.PyTorch Workflow Fundamentals",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**A PyTorch Workflow**\n1. Get data ready (turn into tensors)\n2. Build or pick a pretrained model (to suit your problem)\n   \n   2.1 Pick a loss function & optimizer\n   \n   2.2 Build a training loop\n4. Fit the model to the data and make a prediction\n5. Evaluate the model\n6. Improve through experimentation\n7. Save and reload your trained model ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We're going to get ```torch```, ```torch.nn``` and ```matplotlib```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nfrom torch import nn\nimport matplotlib.pyplot as plt",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 1.Data (preparing and loading)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create *known* parameters\nweight = 0.7\nbias = 0.3\n\n# Create data\nstart = 0\nend = 1\nstep = 0.02\nX = torch.arange(start, end, step).unsqueeze(dim=1)\ny = weight * X + bias\n\nX[:10], y[:10]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (tensor([[0.0000],\r\n         [0.0200],\r\n         [0.0400],\r\n         [0.0600],\r\n         [0.0800],\r\n         [0.1000],\r\n         [0.1200],\r\n         [0.1400],\r\n         [0.1600],\r\n         [0.1800]]),\r\n tensor([[0.3000],\r\n         [0.3140],\r\n         [0.3280],\r\n         [0.3420],\r\n         [0.3560],\r\n         [0.3700],\r\n         [0.3840],\r\n         [0.3980],\r\n         [0.4120],\r\n         [0.4260]]))",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Split data into training and test sets",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Split             |Purpose                                                                                      |Amount of total data        |How often is it used?                                                                                                                             |\n|------------------|-----------------------------------------------------------------------------------------|-------|--------------------|\n|**Training set**  |The model learns from this data (like the course materials you study during the semester).   |~60-80%|Always              |\n|**Validation set**|The model gets tuned on this data (like the practice exam you take before the final exam).   |~10-20%|Often but not always|\n|**Testing set**   |The model gets evaluated on this data to test what it has learned (like the final exam).     |~10-20%|Always              |",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create train/test split\ntrain_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\nX_train, y_train = X[:train_split], y[:train_split]\nX_test, y_test = X[train_split:], y[train_split:]\n\nlen(X_train), len(y_train), len(X_test), len(y_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: (40, 40, 10, 10)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's create a function to visualize it.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def plot_predictions(train_data=X_train,\n                     train_labels=y_train,\n                     test_data=X_test,\n                     test_labels=y_test,\n                     prediction=None):\n    plt.figure(figsize=(10, 7))\n    \n    # Plot training data in blue\n    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n    \n    # Plot test data in green\n    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n    \n    if predictions is not None:\n        # Plot the predictions in red\n        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n        \n    # Show the legend\n    plt.legend(prop={\"size\":14});\n\nplot_predictions();",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 2.Build model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a Linear Regression model class\nclass LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n    def __init__(self):\n        super().__init__() \n        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n                                                dtype=torch.float), # <- PyTorch loves float32 by default\n                                   requires_grad=True) # <- can we update this value with gradient descent?)\n\n        self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n                                            dtype=torch.float), # <- PyTorch loves float32 by default\n                                requires_grad=True) # <- can we update this value with gradient descent?))\n\n    # Forward defines the computation in the model\n    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### PyTorch model building essentials",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "PyTorch has 4 essential modules you can use to create almost any kind of neural network you can image. They are ```torch.nn```, ```torch.optim```, ```torch.utils.data.Dataset``` and ```torch.utils.data.DataLoader```.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Almost everything in a PyTorch neural network comes from ```torch.nn```,\n* ```nn.Module``` contains the larger building blocks(layers)\n* ```nn.Parameter``` contains the **smaller parameters** like weights and biases(put these together to make ```nn.Module```(s))\n* ```forward()``` tells the larger blocks **how to make calculations on inputs**(tensors full of data) within ```nn.Module```(s)\n* ```torch.optim``` contains optimization methods on how to improve the parameters within ```nn.Parameter``` to better represent input data",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Checking the contents of a PyTorch model",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now let's create a model instance with the class we've made and **check its parameters** using ```.parameters()```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Set manual seed since nn.Parameter are randomly initialzied\ntorch.manual_seed(42)\n\n# Create an instance of the model\nmodel_0 = LinearRegressionModel()\n\n# Check the nn.Parameter(s) within the nn.Module subclass we created \nlist(model_0.parameters())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: [Parameter containing:\r\n tensor([0.3367], requires_grad=True),\r\n Parameter containing:\r\n tensor([0.1288], requires_grad=True)]",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can also get the state of the model using ```.state_dict()```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# List named parameters\nmodel_0.state_dict()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Making predictions using ```torch.inference_mode()```",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "When we pass data to our model it'll go through the model's ```forward()``` method and produce a result using the computatuin we've defined.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Make predictions with model\nwith torch.inference_mode():\n    y_preds = model_0(X_test)\n\n# Note: in older PyTorch code you might also see torch.no_grad()\nwith torch.no_grad():\n    y_preds = model_0(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Note: In older PyTorch code, you may also see ```torch.no_grad()``` being used for inference. While ```torch.inference_mode()``` and ```torch.no_grad()``` do **similar** things, ```torch.inference_mode()``` is newer, potentially **faster and preferred**. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 3.Train model",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Creating a loss function and optimizer in PyTorch",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Function|What does it do?|Where does it live in PyTorch?|Common values|\n|--------|----------------|------------------------------|-------------|\n|**Loss function**|Measures how wrong your models predictions are compared to the truth labels.|PyTorch has plenty of built-in loss functions in ```torch.nn```.|Mean absolute error (MAE) for regression problems (```torch.nn.L1Loss()```). Binary cross entropy for binary classification problems (```torch.nn.BCELoss()```).|\n|**Optimizer**|Tells your model how to update its internal parameters to best lower the loss.|You can find various optimization function implementations in ```torch.optim```.|Stochastic gradient descent (```torch.optim.SGD()```). Adam optimizer (```torch.optim.Adam()```).|",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create the loss function\nloss_fn = nn.L1Loss()\n\n# Create the optimizer\noptimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n                            lr=0.01)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Creating an optimization loop in PyTorch",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "It's time to create a **training loop**(and **testing loop**).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The training loop involves the model going through the training data and learning the relationships between the ```features``` and ```labels```.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The testing loop involves going through the testing data and evaluating how good the patterns are that the model learned on the training data.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### PyTorch training loop",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Number|Step name|What does it do?|Code example|\n|------|---------|----------------|------------|\n|1|Forward pass|The model goes through all of the training data once, performing its ```forward()``` function calculations.|```model(x_train)```|\n|2|Calculate the loss|The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are.|```loss = loss_fn(y_pred, y_train)```|\n|3|Zero gradients|The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step.|```optimizer.zero_grad()```|\n|4|Perform backpropagation on the loss|Computes the gradient of the loss with respect for every model parameter to be updated (each parameter with ```requires_grad=True```). This is known as **backpropagation**, hence \"backwards\".|```loss.backward()```|\n|5|Update the optimizer (**gradient descent**)|Update the parameters with ```requires_grad=True``` with respect to the loss gradients in order to improve them.|```optimizer.step()```|",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Note: On the ordering of things, the above is a good default order but you may see slightly different orders. Some rules of thumb:\n* Calculate the loss (```loss = ...```) before performing backpropagation on it (```loss.backward()```).\n* Zero gradients (```optimizer.zero_grad()```) before stepping them (```optimizer.step()```).\n* Step the optimizer (```optimizer.step()```) after performing backpropagation on the loss (```loss.backward()```).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Pytorch testing loop",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Number|Step name|What does it do?|Code example|\n|------|---------|----------------|------------|\n|1|Forward pass|The model goes through all of the testing data once, performing its ```forward()``` function calculations.|```model(x_test)```|\n|2|Calculate the loss|The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are.|```loss = loss_fn(y_pred, y_test)```|\n|3|Calulate evaluation metrics (optional)|Alongisde the loss value you may want to calculate other evaluation metrics such as accuracy on the test set.|Custom functions|",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Notice the testing loop **doesn't contain performing backpropagation** ( ```loss.backward()```) or **stepping the optimizer** (```optimizer.step()```), this is because no parameters in the model are being changed during testing, they've already been calculated. For testing, we're only interested in the output of the forward pass through the model.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's put all of the above together and train out model for 100 epochs(forward passes through the data) and we'll evaluate it every 10 epochs.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "torch.manual_seed(42)\n\n# Set the number of epoches (how many times the model will pass over the training data)\nepochs = 100\n\n# Create empty loss lists to track values\ntrain_loss_values = []\ntest_loss_values = []\nepoch_count = []\n\nfor epoch in range(epochs):\n    ### Training\n\n    # Put model in training mode (this is the default state of a model)\n    model_0.train()\n    \n    # 1. Forward pass on train data using forward() method inside\n    y_pred = model_0(X_train)\n    \n    # 2. Calculate the loss \n    loss = loss_fn(y_pred, t_train)\n    \n    # 3. Zero grad of the optimizer\n    optimizer.zero_grad()\n    \n    # 4. Loss backwards\n    loss.backward()\n    \n    # 5. Progress the optimizer\n    optimizer.step()\n\n    ### Testing\n\n    # Put the model in evaluation mode\n    model_0.eval()\n\n    with torch.inference_mode():\n        # 1. Forward pass on test data\n        test_pred = model_0(X_test)\n\n        # 2. Calculate loss on test data\n        test_loss = loss_fn(test_pred, y_test.type(torch.float))\n        \n        # Print out what's happening\n        if epoch % 10 == 0:\n            epoch_count.append(epoch)\n            train_loss_values.append(loss.detach().numpy())\n            test_loss_values.append(test_loss.detach().numpy())\n            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.48106518387794495 \r\nEpoch: 10 | MAE Train Loss: 0.1976713240146637 | MAE Test Loss: 0.3463551998138428 \r\nEpoch: 20 | MAE Train Loss: 0.08908725529909134 | MAE Test Loss: 0.21729660034179688 \r\nEpoch: 30 | MAE Train Loss: 0.053148526698350906 | MAE Test Loss: 0.14464017748832703 \r\nEpoch: 40 | MAE Train Loss: 0.04543796554207802 | MAE Test Loss: 0.11360953003168106 \r\nEpoch: 50 | MAE Train Loss: 0.04167863354086876 | MAE Test Loss: 0.09919948130846024 \r\nEpoch: 60 | MAE Train Loss: 0.03818932920694351 | MAE Test Loss: 0.08886633068323135 \r\nEpoch: 70 | MAE Train Loss: 0.03476089984178543 | MAE Test Loss: 0.0805937647819519 \r\nEpoch: 80 | MAE Train Loss: 0.03132382780313492 | MAE Test Loss: 0.07232122868299484 \r\nEpoch: 90 | MAE Train Loss: 0.02788739837706089 | MAE Test Loss: 0.06473556160926819 ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 4.Making predictions with a trained PyTorch model",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "There are 3 things to remember when making predictions with a PyTorch model:\n1. Set the model in evaluation mode (```model.eval()```).\n2. Make the predictions using the inference mode context manager (```with torch.inference_mode():...```).\n3. All predictions should be made with objects on the same device.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# 1. Set the model in evaluation mode\nmodel_0.eval()\n\n# 2. Setup the inference mode context manager\nwith torch.inference_mode():\n  # 3. Make sure the calculations are done with the model and data on the same device\n  # in our case, we haven't setup device-agnostic code yet so our data and model are\n  # on the CPU by default.\n  # model_0.to(device)\n  # X_test = X_test.to(device)\n  y_preds = model_0(X_test)\ny_preds",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "tensor([[0.8141],\r\n        [0.8256],\r\n        [0.8372],\r\n        [0.8488],\r\n        [0.8603],\r\n        [0.8719],\r\n        [0.8835],\r\n        [0.8950],\r\n        [0.9066],\r\n        [0.9182]])",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 5.Saving and loading a PyTorch model",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For saving and loading models in PyTorch, there are 3 main methods you should be aware of:\n|PyTorch method|What does it do?|\n|--------------|----------------|\n|```torch.save```|Saves a serialized object to disk using Python's ```pickle``` utility. Models, tensors and various other Python objects like dictionaries can be saved using ```torch.save```.|\n|```torch.load```|Uses ```pickle```'s unpickling features to deserialize and load pickled Python object files (like models, tensors or dictionaries) into memory. You can also set which device to load the object to (CPU, GPU etc).|\n|```torch.nn.Module.load_state_dict```|Loads a model's parameter dictionary (```model.state_dict()```) using a saved ```state_dict()``` object.|",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Saving a PyTorch model's ```state_dict()```",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The **recommended** way for saving and loading a model for inference is by saving and loading a model's ```state_dict()```.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's see how we can do that in a few steps:\n1. We'll **create a directory for saving models** to called ```models``` using Python's ```pathlib``` module.\n2. We'll **create a file path to save the model** to.\n3. We'll call ```torch.save(obj, f)``` where ```obj``` is the target model's ```state_dict()``` and ```f``` is the filename of where to save the model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pathlib import Path\n\n# 1. Create models directory\nMODEL_PATH = Path(\"models\")\nMODEL_PATH.mkdir(parents=True, exist_ok=True)\n\n# 2. Create model save path\nMODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\nMODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n\n# 3. Save the model state dict \nprint(f\"Saving model to: {MODEL_SAVE_PATH}\")\ntorch.save(obj=model_0.state_dict(), # only saving the state_dict() only saves the models learned parameters\n           f=MODEL_SAVE_PATH)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Output: Saving model to: models/01_pytorch_workflow_model_0.pth",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Check the saved file path\n!ls -l models/01_pytorch_workflow_model_0.pth",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "-rw-rw-r-- 1 daniel daniel 1063 Nov 10 16:07 models/01_pytorch_workflow_model_0.pth",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Loading a saved PyTorch model's ```state_dict()```",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Since we've now got a saved model ```state_dict()``` at ```models/01_pytorch_workflow_model_0.pth``` we can now load it in using ```torch.nn.Module.load_state_dict(torch.load(f))``` where ```f``` is the filepath of our saved model ```state_dict()```.\n\nWhy call ```torch.load()``` inside ```torch.nn.Module.load_state_dict()```?\n\nBecause we only saved the model's ```state_dict()``` which is a dictionary of learned parameters and not the entire model, we first have to load the ```state_dict()``` with ```torch.load()``` and then pass that ```state_dict()``` to a new instance of our model (which is a subclass of ```nn.Module```).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Instantiate a new instance of our model (this will be instantiated with random weights)\nloaded_model_0 = LinearRegressionModel()\n\n# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)\nloaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 6.Putting it all together",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. We'll start by **importing the standard libraries** we need.\n2. Setup device (```device = \"cuda\" if torch.cuda.is_available() else \"cpu\"```)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 6.1 Data\n\n1. Create some data\n2. Split data into training and test sets\n3. Visualize",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 6.2 Building a PyTorch linear model\n\n1. Make a model\n2. Put the model on the GPU",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 6.3 Training\n\n1. Create a loss function and optimizer\n2. Based on PyTorch training loop steps, train the model",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 6.4 Making predictions\n\nWe've got a trained model, let's turn on it's evaluation mode and make some predictions.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 6.5 Saving and loading a model\n\n",
      "metadata": {}
    }
  ]
}